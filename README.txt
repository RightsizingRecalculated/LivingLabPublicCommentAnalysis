9/16 NOTES ON NEW DATA RELEASED ON 9/14 and 9/10

The city has released another set of new data with more correspondence received through 9/14. Thankfully, the Living Lab staff are now not just reusing the same filenames and  are making it a bit clearer on the websiute as to when they've last updated the summary of feedback spreadsheet (though the filename suggests it was on 9/14 and the website says 9/11!). The quality of the dataset in the spreadsheet is continuing to improve: there are now individual boolean columns for each corridor in addition to the corridor column, date and corridor typos seem to have been cleaned up, etc.  And staff have started to report the same statiscal breakdown and percentages for the same 3 datasets that the Camera reported on: All comments since May 7, the subset of Folsom corridor comments since May 7, and a smaller subset of Folsom corridor comments since July 13 (the installation date). But there is still no explanation of why 300 comments suddenly appeared on 9/2 that weren't there on 8/26.  

The city does continue to report the Inspire Boulder data in a separate spreadsheet and have neither coded it for Reaction nor included it in the datasets and percentages they report on the website. That spreadsheet was now updated on 9/10, and includes 76 additional comments which presumably (there is no date column) are new since 8/26. Oddly the Inspire Boulder Folsom Street feedback topic closed this past weekend, and a SurveyGizmo link has popped up in its place. I am not sure why the change in instrument was made.

I ran my usual analysis on their spreadsheets and have come up with revised percentages that are more updated than data I currently see on the Living Lab site. I also added the results of my coding the 411 Inspire Boulder comments to the coding done by city to get as complete and accurate figures as the public data will allow. I did make one methodological change--I am no longer coding the Inspire Boulder for the corridors targeted but just considering it all as Folsom corridor related (and since 7/13). My justifcation for that was that we now know how the city is building their data subset (i.e. we know the they are not excluding comments treating both Folsom & Iris from their "Folsom" data subset and are using 7/13 as the cutoff date).

There are also small differences between my methodology and that of the city--the city's calculations appear to be omitting some correspondence where the Reaction column has been left blank, for instance. Those should not be significant, but might account for slight reporting differences both for the total n and for the percentages.

9/18 RESULTS 

The most recent analysis and dataset is in the 20150916RightSizingRecalculated.xlsx (and .ods) files.

The biggest change in the datasets is that the "Folsom correspondence since 7/13" data subset is now about 49% positive to 46% negative as opposed to 57% positive to 40% negative.  And if one adds in the 411  InspireBoulder comments (at least as I have coded them), one sees those percentages narrow a little more: 48.5% positive to 47.5% negative. This is because the more recent feedback trends more negative, and the Inspire Boulder feedback continues to run at 60%+ negative to only about 35% positive.

The larger datasets show smaller shifts (as one would expect). All correspondence feedback is running at 54% negative to 42% positive, and if we include the Inspire Boulder comments the total feedback recieved is now 55% negative to 40% positive. The middle-sized dataset of Folsom follows a similar pattern of a shift toward a negative reaction.

9/18 CONCLUSIONS

Staff is no longer selectively reporting the public comment data on the Living Lab website, and that is a very welcome improvement. It will be interesting to observe how staff behaves next time they present this data to council. I see staff is also now releasing their weekly update letters to council, in which the one dated 9/4 shows that staff is also finally presenting the percentages on all the public comment data they omitted from the presentation to council on 8/25.

So it appears that the criticisms that were made first here and then by the Camera have struck home with staff, and on the web we are getting a more complete disclosure on the part of staff re all the public comment, and not just a subset of it.  But it is remains curious that the inspire Boulder comments have not been coded and incorporated into the quantitative analysis.

The public comment datasets are showing that after a swing of the needle to the positive direction just after the installation of the Folsom project, public comment is again trending negative. This could represent a return to previous trends due to a false "surge" coinciding with the timing of the publicity campaign by the pro-bike/anti-car group the Camera discussed in detail. Or maybe the needle will swing again. Time will tell.

Thanks to everyone who emailed and offered to help, but I would prefer to keep this anonymous and a one-person band--mainly because I just don't trust city staff and council not to retaliate against me. I'll update sporadically as I do have a job.

Comments are welcome to RightsizingRecalculated@email.com

-----

Previous info follows.

----

SOME NOTES ON 9/10

Thanks to the 9/6 Camera article over the Labor Day weekend, I think I can finally see how the Living Lab staff built the subset of public comments on which they made the claim that comment ran 57% positive to 40% negative. The reporting indicated that the city staff reported on only that subset of comments directed at Folsom that were after 7/13, the date the rightsizing was installed on Folsom. By sorting by date and targeting all Folsom corridor-related comments (ie excluding only the ones directed at 55th, 63rd, Iris or some combination of only those other corridors), I can get pretty darn close to the total number of comments in the datasets reported in the Camera--although still not exactly.  

The reason these calculations do not match those the city provided to the Camera appears to be that the city's new excel dataset contains an additional 22 comments when compared to what the city released to the Camera (in all conditions). However, when I count the positive and negative comments my calculations are quite close to the staff's percentages. I do not have a good explanation yet for why these datasets don't match exactly--nor have I seen city staff come forward to explain why there are 315 more public comments in the 9/2 excel dataset than were in the original pdf released on 8/26.

I am relieved to read that my initial idea of how staff was getting to their dataset (that staff was counting Folsom-only comments) was wrong. But why do only those comments on rightsizing made after the installation of it on Folsom matter? 

If it hadn't been for the form letter, I suppose one could argue that they might reflect a shift in public opinion--namely that it just isn't as bad as people thought it would be. But if we analyze the spreadsheets without the form letters (and they make up roughly a third of the positive public comment after 7/13) it turns out that the public comment is pretty consistent both before and after installation--negative overall and slightly positive on Folsom.

So even after digesting this explanation of how the city got to its analysis, I still find staff's choice to ONLY report on the public comment elicited from 7/13 forward to be highly questionable. I am very glad the Camera placed the city's claims in context, and now we know how GoBoulder staff went about not telling the whole truth about the public comment on rightsizing. I still stand by the final two paragraphs of my previous conclusion:

"In not reporting the statistical breakdown of all the public comment, and by making arbitrary and highly questionable decisions on which public comments to exclude. In doing so, GoBoulder’s Kathleen Bracke did not convey the public comment to council in a fair and impartial way; instead, by picking the most favorable subset of the public comment they could, GoBoulder staff indisputably acted as partisan advocates for the rightsizing project. 

That was wrong; city staff should not selectively report on public comment to advance an  agenda of their own."

Thanks very much to all of you commented and offered to help. I still prefer to remain anonymous because I don't trust city staff and/or council not to retaliate against me.


------

FROM INITIAL ANALYSIS ON 9/2

On 9/2/2015 the Living Lab staff updated their website to provide a different "Summary of Community Feedback" pdf than the original "Summary of Feedback" pdf with which this project began. Staff also very kindly provided it in excel spreadsheet format, making it much easier for an independent party to tabulate. This dataset does not include the 335 comments in the Inspire Boulder worksheet; instead, it contains previously unpublished public comments.

Note that this dataset of public comments is different than the dataset that the city previously provided. It contains at least 315 comments that were not in the original pdf, which contained only 1606. There are now 1921 total comments. I have not been able to yet determine if any comments were deleted (duplicates). Some comments appear to have been classified differently in today documents than they were the original—for example, there are no more “mixed” classifications in the Reaction column.

The data also seems to have been cleaned up from the original pdf released on 8/25/15.  In any cases the date of comment has been changed (sometimes this is clearly a correction, i.e. for comments dated in 2011, but often less clearly so). There is more regularity in the Corridor column, where almost all typos much as “Folso m” present in the previous document have been fixed, and variations in the field has been better normalized (i.e. “folsom” and “Folsom” have been all changed to “Folsom Street”). Some of the other columns have been similarly normalized. A few typos remain.

I have determined that the new comments were from the following sources (24 were from Inquire Boulder, a “Method of Contact” not present at all in the original pdf; there are two additional telephone contacts, and the balance (approximately 289) are emails. Most of those newly released emails (at least 211) appear to have been generated from a form letter on the People For Bikes website (the agency at which the previous GoBoulder manager Martha Roskowski now works).  The content of these new emails are nearly identical, as can be expected from a form letter. I am less concerned about a non-profit’s use of a form email letter generator (normal in these sorts of public comment periods) than I am with the city’s suddenly “discovering” these emails and posting them after the fact, without acknowledging that there had been a mistake in the original release of public comments. But the source of these emails does make it clear why the percentages in the city’s newly released data skew more positive than what they originally released.

RESULTS AND DISCUSSION:

Despite the large number of positive and largely form emails the city has found, when all comments are considered the newly revised statistical breakdown is 53% negative to 41% positive. Staff did not choose to present this breakdown of the 1921 total comments to council.

Using the revised dataset I was able to build a subset marked as “Folsom street” only of 977 public comments, which is close to the approximate 950 comments GoBoulder staff mentioned to council. That is 325 more comments than I had found in the original pdf, which suggests that some revisions have been made to the corridor classification of previously released comments. Since the vast majority of the new released form emails were positive and directed at Folsom, the percentages of the Folsom-only subset from the original pdf have changed dramatically. Using the city’s newly released data, I now calculate the Folsom-only percentages at 58% positive to 39% negative. 

While that’s reasonably close to the 57% positive 40% negative staff reported, I am still concerned that staff chose to report only that statistical breakdown to council. By reporting public comments marked as “Folsom Street” ONLY, staff has chosen to exclude a large number of comments that are clearly addressed to, for example, both Folsom and Iris, or at all corridors. As I have shown in the original analysis, excluding other corridors from the analysis makes the public comments seem more positive about rightsizing on Folsom than the public comment actually is. In fact, under almost any other set of criteria the public comment skews negative.

Finally, I am a bit surprised that the 335 Inspire Boulder comments have not yet been incorporated into the counts, though my (preliminary) analysis showed them skewing negative on Folsom and would have been a nice additional piece of data to include in the percentages presented to council. And of course, there are some coding errors (a few positive comments that are clearly misclassified positive or neutral; and vice versa), but not enough to appear statistically significant so that is not a worry I presently have.

CONCLUSIONS:

As a statistician, I am relieved to say that the mystery of how GoBoulder staff calculated their percentages now appears to have been solved. Although I am somewhat suspicious of the city’s sudden discovery of previously unreleased emails, that much could have been an inadvertent error. The original pdf did not contain data that supported that statistical breakdown, but the newly released (9/2) pdf and excel files render the breakdown in the 8/25 presentation to council statistically plausible.

But I am also now more certain than before that GoBoulder staff have not telling the whole truth about the public comment on rightsizing. In not reporting the statistical breakdown of all the public comment, and by making arbitrary and highly questionable decisions on which public comments to exclude. In doing so, GoBoulder’s Kathleen Bracke did not convey the public comment to council in a fair and impartial way; instead, by picking the most favorable subset of the public comment they could, GoBoulder staff indisputably acted as partisan advocates for the rightsizing project. 

That was wrong; city staff should not selectively report on public comment to advance an  agenda of their own.


NOTES:

The original "Summary of Feedback" pdf has now vanished from the Living Lab wesite, but it is preserved in the Step 1 folder inside of the StepByStep folder. 

Due to the late hour, the publication of the supporting analysis (spreadsheets, etc.) will have to wait until another day. There’s a lot of careful cleanup to do and I do have a day job.

Comments are welcome to RightsizingRecalculated@email.com

—————

The original readme.txt follows.  Note that given the city’s newly released additional public comments, it appears that adding the 335 public comments from Inspire Boulder was misguided.

--------------------

On Aug 25th, at the Boulder City Council Study Session, Kathleen Bracke from the GoBoulder staff presented a statistical breakdown of approximately 950 public comments on the Folsom corridor 'right'-sizing in which she claimed that the public comments were 57% positive to 40% negative, suggesting that the public comment was supportive of the 'right'-sizing.

That is not true.  

An alert reader of the Camera commented that a word search of the "Summary of Feedback" pdf indicated that the word "negative" occured almost twice as often as the word "positive". The reader noted that not all of those occured in the "Reaction" column of pdf where staff classified the comment as negative or positive, but most did.

That inspired me to do this project. Over the past 5 days I have gathered all the public comments that were published on the Living Laboratory website and put them together as a single dataset in a spreadsheet.

This spreadsheet demonstrates that the public comment on the Folsom-corridor rightsizing is actually 50% negative to 43% positive.

GoBoulder staff noted that they had received approximately 1900 public comments on 'right'-sizing, but did not supply a  statistical breakdown for all the public comments received.

This spreadsheet shows that for all 1944 published public comments on 'right'-sizing regardless of corridor, 59% were negative while only 35% were positive.

But don't take my word for it. Look through this spreadsheet, sort and play with the data. Look carefully at the original pdfs from the Living Lab website. Retrace the steps I performed as I did this analysis.



